{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "client = get_client(url=\"http://localhost:8123\")\n",
    "async for chunk in client.runs.stream(\n",
    "    None,\n",
    "    \"simple-agent\",\n",
    "    input={\"messages\": [{\"role\": \"human\", \"content\": \"Hi, who are you?\"}]},\n",
    "    stream_mode=\"events\"\n",
    "):\n",
    "    content = chunk.data.get(\"data\", {}).get(\"chunk\", {}).get(\"content\")\n",
    "    if content:\n",
    "        print(content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Modes - ('values', 'messages', 'updates', 'events', 'debug', 'custom', 'messages-tuple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello\n",
      "Hello!\n",
      "Hello! How\n",
      "Hello! How can\n",
      "Hello! How can I\n",
      "Hello! How can I assist\n",
      "Hello! How can I assist you\n",
      "Hello! How can I assist you today\n",
      "Hello! How can I assist you today?\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    None,\n",
    "    \"simple-agent\",\n",
    "    input={\"messages\": [{\"role\": \"human\", \"content\": \"Hi\"}]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if isinstance(chunk.data, list):\n",
    "        print(chunk.data[0]['content'], flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm an AI language model created by OpenAI, designed to assist with a wide range of queries by providing information and answering questions to the best of my ability. How can I help you today?"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    None,\n",
    "    \"simple-agent\",\n",
    "    input={\"messages\": [{\"role\": \"human\", \"content\": \"Hi, who are you?\"}]},\n",
    "    stream_mode=\"events\"\n",
    "):\n",
    "    content = chunk.data.get(\"data\", {}).get(\"chunk\", {}).get(\"content\")\n",
    "    if content:\n",
    "        print(content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1f004fb5-dd27-685e-a2af-271949f35c24', 'attempt': 1})\n",
      "****\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Hi', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'e67d770c-a3ab-4a92-af9b-3f3af16242e5', 'example': False}]})\n",
      "****\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Hi', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'e67d770c-a3ab-4a92-af9b-3f3af16242e5', 'example': False}, {'content': 'Hello! How can I assist you today?', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6ec83003ad', 'id': 'chatcmpl-BCtiVxkT2C4KAXbdABylZizC77XXl', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-0be9e3a0-352b-4f79-a73b-0e9cbcdcbbdd-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    None,\n",
    "    \"simple-agent\",\n",
    "    input={\"messages\": [{\"role\": \"human\", \"content\": \"Hi\"}]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "   print(chunk, end = \"\\n****\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
